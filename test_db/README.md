# Задание по выбору хранилища

В качестве кандидатов для выбора хранилища для обработки аналитических данных были выбраны ClickHouse и Vertica. 
Были преприняты так же попытки протестировать CassandraDB, однако уже на 2млн записей Cassandra отказывалась исполнять какие-либо запросы на чтение за разумное время. По этой причине в тестах она не участвовала.

Условия тестов:
Ресурсы контейнера для БД - 4гб оперативной памяти, 4 CPU,
до начала тестов в контейнер помещались 10млн записей, по 1000 уникальных UUID для пользователей и фильмов

Описания тестов:
- `select_average_timestamps` - достать `id` всех фильмов со средним временем их просмотра
- `select_max_timestamp_by_user_movie` - достать timestamp, на котором остановился пользователь при просмотре фильма
- `select_max_timestamps_by_user` - достать timestamp-ы, на которых остановился пользователь для всех фильмов
- `select_movies_by_user` - достать id фильмов, которые просматривал пользователь
- `select_users_by_movie` - достать id пользователей, которые просматривали фильм
- `insert_batch_{batch_size}` - вставка батча

Описания схем и запросов доступны в папках с тестами соответствующих баз.

Для тестирования запросов под нагрузкой запускался дополнительный процесс, генерирующий 100 запросов на вставку в секунду.
Размер батча для ClickHouse - 100 записей. Для нагрузки в 200 рпс запускался еще один такой процесс. 
Для Vertica из-за низкой скорости вставки, записи в нагрузке вставлялись по одной.

## Результаты тестов
### ClickHouse
| Тест | Без нагрузки, мс | 100 RPS, мс | 200 RPS, мс |
|---|:---:|:---:|:---:|
| `select_average_timestamps` | 98.02+-31.12 | 123.54+-28.84 | 228.42+-121.72 |
| `select_max_timestamp_by_user_movie` | 9.18+-9.32 | 9.07+-6.02 | 11.99+-6.08 |
| `select_max_timestamps_by_user` | 8.06+-6.65 | 7.78+-1.92 | 19.91+-26.86 |
| `select_movies_by_user` | 8.49+-8.80 | 11.47+-8.81 | 11.83+-4.81 |
| `select_users_by_movie` | 98.43+-40.43 | 93.88+-19.81 | 192.25+-46.38 |
| `insert_batch_1` | 5.56+-2.05 | 5.54+-1.86 | 12.51+-10.29 |
| `insert_batch_100` | 5.99+-1.76 | 6.46+-2.45 | 8.73+-4.54 |
| `insert_batch_1000` | 11.43+-2.16 | 12.95+-9.67 | 17.55+-8.20 |

### Vertica
| Тест | Без нагрузки, мс | 100 RPS, мс | 200 RPS, мс |
|---|:---:|:---:|:---:|
| `select_average_timestamps` | 359.26+-77.51 | 450.14+-101.27 | 525.49+-167.98 |
| `select_max_timestamp_by_user_movie` | 40.67+-22.33 | 57.86+-27.65 | 81.93+-23.15 |
| `select_max_timestamps_by_user` | 61.74+-28.09  | 75.33+-23.16 | 101.25+-33.47 |
| `select_movies_by_user` | 55.02+-45.89 | 63.57+-33.12 | 84.16+-38.16 |
| `select_users_by_movie` | 176.06+-17.47 | 215.86+-35.16 | 248.61+-53.16 |
| `insert_batch_1` | 15.49+-8.85 | 16.11+-8.11 | 26.17+-11.23 |
| `insert_batch_100` | 839.55+-320.43 | 897+-319.18 | 965.37+-387.84 |
| `insert_batch_1000` | 8208.69+-1390.00 | 8265.92+-1187.21 | 8306.98+-1374.16 |

Как видно по данным, при схожих параметрах, в запросах на получение данных Clickhouse обгоняет Vertica в разы, а на вставку на порядки.
По этим причинам для дальнейшей работы в качестве аналитической базы данных был выбран Clickhouse.

## Выбор хранилища для пользовательских оценок, закладок и обзоров
В рамках этой задачи необходимо было решить, можно ли воспользоваться БД, использующейся для аналитики (Clickhouse) или воспользоваться другим решением.
В качестве альтернативы была рассмотрена MongoDB.
База должна хранить следующие коллекции:
- `estimations` - оценка фильма пользователем, данные - `user_id`, `movie_id`, `estimation` - оценка от 0 до 10,
- `postponed` - закладки пользователя - пары `user_id`, `movie_id`,
- `reviews` - обзоры - `author_id`, `movie_id`, `published_at`, `text`,
- `reviews_estimations` - `user_id`, `review_id`, `estimation`.

Если исходить из предположения, что охват кинотеатром аудитории <10^6, то количество оценок должно быть порядка 10^7,
оценок 10^7, обзоров 10^6, оценок обзоров 10^7.
Если предположить, что вес записи об оценке фильма - 150 байт, закладки - 150 байт, оценки обзора - 150 байт, обзора - 10000 байт (значения получены эмпирическим путем),
то требуемый объем БД составляет около 15 Гб.

Скорость обработки запросов тестировалась на следующих кейсах:
- `user_favorites` - список id любимых фильмов пользователя, фильм считается любимым если его оценка > 7,
- `movie_likes` - количество лайков у фильма,
- `postpones` - список отложенных пользователем фильмов
- `average_score` - средняя оценка фильма

Перед тестами БД заполнялась данными в количестве, представленном выше. Описание процесса запуска скриптов приведено [здесь](test_mongo/README.md).

### Результаты:

| Тест | Без нагрузки, мс | 100 RPS, мс |
|---|:---:|:---:|
| `user_favorites` | 7266.91+-1519.03 | 5680.00+-932.15 |
| `movie_likes` | 6694.49+-1450.59 | 7948.25+-2862.49 |
| `postpones` | 7971.68+-9740.77  | 6532.96+-1552.91 |
| `average_score` | 5063.19+-1687.94 | 10566.03+-1594.58 |

По результатам тестов видно, что нагрузка в 100 рпс не оказывает серьезного влияния на производительность БД. Единственным запросом, время обработки которого серьезно возросло - подсчет среднего рейтинга фильма.
Хотя точно таких же тестов для Clickhouse не производилось, можно считать, что тесты `select_movies_by_user` и `select_average_timestamps` будут аналогичны по сложности `user_favorites`, `postpones` и `average_score`.
По ним видно, что при прочих равных Clickhouse обрабатывает запросы на порядок быстрее.
В дальнейшем предполагается работа с Clickhouse.